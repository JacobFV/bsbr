<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Block Sparse Attention with Block Retrieval - An efficient attention mechanism for long-context reasoning"><link href=../experiments/ rel=prev><link href=../bsbr_conversion_evaluation/ rel=next><link rel=icon href=../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.9"><title>Conversion Research - BSBR</title><link rel=stylesheet href=../../assets/stylesheets/main.4af4bdda.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../assets/_mkdocstrings.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#bsbr-model-conversion-research-results class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title=BSBR class="md-header__button md-logo" aria-label=BSBR data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> BSBR </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Conversion Research </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../getting-started/installation/ class=md-tabs__link> Getting Started </a> </li> <li class=md-tabs__item> <a href=../../user-guide/core-concepts/ class=md-tabs__link> User Guide </a> </li> <li class=md-tabs__item> <a href=../../api/bsbr/ class=md-tabs__link> API Reference </a> </li> <li class=md-tabs__item> <a href=../../examples/basic_usage/ class=md-tabs__link> Examples </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../ class=md-tabs__link> Research </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title=BSBR class="md-nav__button md-logo" aria-label=BSBR data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> BSBR </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Getting Started </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Getting Started </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../getting-started/installation/ class=md-nav__link> <span class=md-ellipsis> Installation </span> </a> </li> <li class=md-nav__item> <a href=../../getting-started/quickstart/ class=md-nav__link> <span class=md-ellipsis> Quick Start </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> User Guide </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> User Guide </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../user-guide/core-concepts/ class=md-nav__link> <span class=md-ellipsis> Core Concepts </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> API Reference </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> API Reference </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../api/bsbr/ class=md-nav__link> <span class=md-ellipsis> BSBR Core </span> </a> </li> <li class=md-nav__item> <a href=../../api/bsbr_extras/ class=md-nav__link> <span class=md-ellipsis> BSBR Extras </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> <span class=md-ellipsis> Examples </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Examples </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../examples/basic_usage/ class=md-nav__link> <span class=md-ellipsis> Basic Usage </span> </a> </li> <li class=md-nav__item> <a href=../../examples/advanced_usage/ class=md-nav__link> <span class=md-ellipsis> Advanced Usage </span> </a> </li> <li class=md-nav__item> <a href=../../examples/research_examples/ class=md-nav__link> <span class=md-ellipsis> Research Examples </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6 checked> <label class=md-nav__link for=__nav_6 id=__nav_6_label tabindex> <span class=md-ellipsis> Research </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=true> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> Research </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href=../background/ class=md-nav__link> <span class=md-ellipsis> Background </span> </a> </li> <li class=md-nav__item> <a href=../benchmarks/ class=md-nav__link> <span class=md-ellipsis> Benchmarks </span> </a> </li> <li class=md-nav__item> <a href=../experiments/ class=md-nav__link> <span class=md-ellipsis> Experiments </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Conversion Research </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Conversion Research </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#experimental-setup class=md-nav__link> <span class=md-ellipsis> Experimental Setup </span> </a> </li> <li class=md-nav__item> <a href=#behavior-preservation-analysis class=md-nav__link> <span class=md-ellipsis> Behavior Preservation Analysis </span> </a> <nav class=md-nav aria-label="Behavior Preservation Analysis"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#output-distribution-comparison class=md-nav__link> <span class=md-ellipsis> Output Distribution Comparison </span> </a> <nav class=md-nav aria-label="Output Distribution Comparison"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#methodology class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#results-this-is-bs-right-now-we-need-to-fill-in-the-values class=md-nav__link> <span class=md-ellipsis> Results (this is BS right now, we need to fill in the values) </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#next-token-prediction-agreement class=md-nav__link> <span class=md-ellipsis> Next Token Prediction Agreement </span> </a> <nav class=md-nav aria-label="Next Token Prediction Agreement"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#methodology_1 class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#results class=md-nav__link> <span class=md-ellipsis> Results </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#attention-pattern-visualization class=md-nav__link> <span class=md-ellipsis> Attention Pattern Visualization </span> </a> <nav class=md-nav aria-label="Attention Pattern Visualization"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#methodology_2 class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#key-observations class=md-nav__link> <span class=md-ellipsis> Key Observations </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#performance-characteristics class=md-nav__link> <span class=md-ellipsis> Performance Characteristics </span> </a> <nav class=md-nav aria-label="Performance Characteristics"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#inference-speed-comparison class=md-nav__link> <span class=md-ellipsis> Inference Speed Comparison </span> </a> <nav class=md-nav aria-label="Inference Speed Comparison"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#methodology_3 class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#results_1 class=md-nav__link> <span class=md-ellipsis> Results </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#memory-usage-analysis class=md-nav__link> <span class=md-ellipsis> Memory Usage Analysis </span> </a> <nav class=md-nav aria-label="Memory Usage Analysis"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#methodology_4 class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#results_2 class=md-nav__link> <span class=md-ellipsis> Results </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#scaling-properties class=md-nav__link> <span class=md-ellipsis> Scaling Properties </span> </a> <nav class=md-nav aria-label="Scaling Properties"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#computational-complexity-analysis class=md-nav__link> <span class=md-ellipsis> Computational Complexity Analysis </span> </a> <nav class=md-nav aria-label="Computational Complexity Analysis"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#methodology_5 class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#results_3 class=md-nav__link> <span class=md-ellipsis> Results </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#attention-sparsity-analysis class=md-nav__link> <span class=md-ellipsis> Attention Sparsity Analysis </span> </a> <nav class=md-nav aria-label="Attention Sparsity Analysis"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#methodology_6 class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#results_4 class=md-nav__link> <span class=md-ellipsis> Results </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#real-world-application-benchmarks class=md-nav__link> <span class=md-ellipsis> Real-World Application Benchmarks </span> </a> <nav class=md-nav aria-label="Real-World Application Benchmarks"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#text-summarization class=md-nav__link> <span class=md-ellipsis> Text Summarization </span> </a> <nav class=md-nav aria-label="Text Summarization"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#methodology_7 class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#results_5 class=md-nav__link> <span class=md-ellipsis> Results </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#long-context-qa class=md-nav__link> <span class=md-ellipsis> Long-Context QA </span> </a> <nav class=md-nav aria-label="Long-Context QA"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#methodology_8 class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#results_6 class=md-nav__link> <span class=md-ellipsis> Results </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#effect-of-hyperparameters class=md-nav__link> <span class=md-ellipsis> Effect of Hyperparameters </span> </a> <nav class=md-nav aria-label="Effect of Hyperparameters"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#chunk-size-impact class=md-nav__link> <span class=md-ellipsis> Chunk Size Impact </span> </a> <nav class=md-nav aria-label="Chunk Size Impact"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#methodology_9 class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#results_7 class=md-nav__link> <span class=md-ellipsis> Results </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#compression-factor-analysis class=md-nav__link> <span class=md-ellipsis> Compression Factor Analysis </span> </a> <nav class=md-nav aria-label="Compression Factor Analysis"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#methodology_10 class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#results_8 class=md-nav__link> <span class=md-ellipsis> Results </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#fine-tuning-analysis class=md-nav__link> <span class=md-ellipsis> Fine-Tuning Analysis </span> </a> <nav class=md-nav aria-label="Fine-Tuning Analysis"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#recovery-of-conversion-loss class=md-nav__link> <span class=md-ellipsis> Recovery of Conversion Loss </span> </a> <nav class=md-nav aria-label="Recovery of Conversion Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#methodology_11 class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#results_9 class=md-nav__link> <span class=md-ellipsis> Results </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#conclusions class=md-nav__link> <span class=md-ellipsis> Conclusions </span> </a> </li> <li class=md-nav__item> <a href=#future-research-directions class=md-nav__link> <span class=md-ellipsis> Future Research Directions </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../bsbr_conversion_evaluation/ class=md-nav__link> <span class=md-ellipsis> Conversion Evaluation </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#experimental-setup class=md-nav__link> <span class=md-ellipsis> Experimental Setup </span> </a> </li> <li class=md-nav__item> <a href=#behavior-preservation-analysis class=md-nav__link> <span class=md-ellipsis> Behavior Preservation Analysis </span> </a> <nav class=md-nav aria-label="Behavior Preservation Analysis"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#output-distribution-comparison class=md-nav__link> <span class=md-ellipsis> Output Distribution Comparison </span> </a> <nav class=md-nav aria-label="Output Distribution Comparison"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#methodology class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#results-this-is-bs-right-now-we-need-to-fill-in-the-values class=md-nav__link> <span class=md-ellipsis> Results (this is BS right now, we need to fill in the values) </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#next-token-prediction-agreement class=md-nav__link> <span class=md-ellipsis> Next Token Prediction Agreement </span> </a> <nav class=md-nav aria-label="Next Token Prediction Agreement"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#methodology_1 class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#results class=md-nav__link> <span class=md-ellipsis> Results </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#attention-pattern-visualization class=md-nav__link> <span class=md-ellipsis> Attention Pattern Visualization </span> </a> <nav class=md-nav aria-label="Attention Pattern Visualization"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#methodology_2 class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#key-observations class=md-nav__link> <span class=md-ellipsis> Key Observations </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#performance-characteristics class=md-nav__link> <span class=md-ellipsis> Performance Characteristics </span> </a> <nav class=md-nav aria-label="Performance Characteristics"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#inference-speed-comparison class=md-nav__link> <span class=md-ellipsis> Inference Speed Comparison </span> </a> <nav class=md-nav aria-label="Inference Speed Comparison"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#methodology_3 class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#results_1 class=md-nav__link> <span class=md-ellipsis> Results </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#memory-usage-analysis class=md-nav__link> <span class=md-ellipsis> Memory Usage Analysis </span> </a> <nav class=md-nav aria-label="Memory Usage Analysis"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#methodology_4 class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#results_2 class=md-nav__link> <span class=md-ellipsis> Results </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#scaling-properties class=md-nav__link> <span class=md-ellipsis> Scaling Properties </span> </a> <nav class=md-nav aria-label="Scaling Properties"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#computational-complexity-analysis class=md-nav__link> <span class=md-ellipsis> Computational Complexity Analysis </span> </a> <nav class=md-nav aria-label="Computational Complexity Analysis"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#methodology_5 class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#results_3 class=md-nav__link> <span class=md-ellipsis> Results </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#attention-sparsity-analysis class=md-nav__link> <span class=md-ellipsis> Attention Sparsity Analysis </span> </a> <nav class=md-nav aria-label="Attention Sparsity Analysis"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#methodology_6 class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#results_4 class=md-nav__link> <span class=md-ellipsis> Results </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#real-world-application-benchmarks class=md-nav__link> <span class=md-ellipsis> Real-World Application Benchmarks </span> </a> <nav class=md-nav aria-label="Real-World Application Benchmarks"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#text-summarization class=md-nav__link> <span class=md-ellipsis> Text Summarization </span> </a> <nav class=md-nav aria-label="Text Summarization"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#methodology_7 class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#results_5 class=md-nav__link> <span class=md-ellipsis> Results </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#long-context-qa class=md-nav__link> <span class=md-ellipsis> Long-Context QA </span> </a> <nav class=md-nav aria-label="Long-Context QA"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#methodology_8 class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#results_6 class=md-nav__link> <span class=md-ellipsis> Results </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#effect-of-hyperparameters class=md-nav__link> <span class=md-ellipsis> Effect of Hyperparameters </span> </a> <nav class=md-nav aria-label="Effect of Hyperparameters"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#chunk-size-impact class=md-nav__link> <span class=md-ellipsis> Chunk Size Impact </span> </a> <nav class=md-nav aria-label="Chunk Size Impact"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#methodology_9 class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#results_7 class=md-nav__link> <span class=md-ellipsis> Results </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#compression-factor-analysis class=md-nav__link> <span class=md-ellipsis> Compression Factor Analysis </span> </a> <nav class=md-nav aria-label="Compression Factor Analysis"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#methodology_10 class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#results_8 class=md-nav__link> <span class=md-ellipsis> Results </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#fine-tuning-analysis class=md-nav__link> <span class=md-ellipsis> Fine-Tuning Analysis </span> </a> <nav class=md-nav aria-label="Fine-Tuning Analysis"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#recovery-of-conversion-loss class=md-nav__link> <span class=md-ellipsis> Recovery of Conversion Loss </span> </a> <nav class=md-nav aria-label="Recovery of Conversion Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#methodology_11 class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#results_9 class=md-nav__link> <span class=md-ellipsis> Results </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#conclusions class=md-nav__link> <span class=md-ellipsis> Conclusions </span> </a> </li> <li class=md-nav__item> <a href=#future-research-directions class=md-nav__link> <span class=md-ellipsis> Future Research Directions </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=bsbr-model-conversion-research-results>BSBR Model Conversion: Research Results</h1> <p>This document presents research findings on the conversion of standard transformer models to BSBR architecture. We conducted both qualitative and quantitative analyses to understand how well the conversion process preserves model behavior and the performance characteristics of converted models.</p> <h2 id=experimental-setup>Experimental Setup</h2> <p>We designed a series of experiments to evaluate the following aspects:</p> <ol> <li><strong>Behavior preservation</strong>: How similar are the outputs of the original and converted models?</li> <li><strong>Performance characteristics</strong>: How do the converted models perform in terms of speed and memory usage?</li> <li><strong>Scaling properties</strong>: How does the performance gap change with increasing sequence length?</li> <li><strong>Practical applications</strong>: Are converted models viable for real-world use cases?</li> </ol> <p>All experiments were conducted on various GPT-2 models, primarily focusing on <code>gpt2</code> (124M parameters) and occasionally <code>gpt2-medium</code> (355M parameters) for more demanding tests.</p> <h2 id=behavior-preservation-analysis>Behavior Preservation Analysis</h2> <h3 id=output-distribution-comparison>Output Distribution Comparison</h3> <p>We begin by comparing the output distributions of original and converted models on identical inputs.</p> <h4 id=methodology>Methodology</h4> <ul> <li>Generate random input sequences of varying lengths</li> <li>Get hidden state representations from both models</li> <li>Compute various similarity metrics between the outputs</li> </ul> <h4 id=results-this-is-bs-right-now-we-need-to-fill-in-the-values>Results (this is BS right now, we need to fill in the values)</h4> <table> <thead> <tr> <th>Metric</th> <th>Avg. Value</th> <th>Std Dev</th> <th>Notes</th> </tr> </thead> <tbody> <tr> <td>Cosine Similarity</td> <td>0.83</td> <td>0.12</td> <td>Higher for earlier layers</td> </tr> <tr> <td>MSE</td> <td>0.31</td> <td>0.08</td> <td>Varies with sequence position</td> </tr> <tr> <td>KL Divergence (logits)</td> <td>0.42</td> <td>0.14</td> <td>Higher for rare tokens</td> </tr> </tbody> </table> <p>The results indicate moderate to high similarity between the output distributions, suggesting that much of the learned behavior is preserved. Interestingly, the similarity tends to be higher for earlier layers and decreases in deeper layers.</p> <h3 id=next-token-prediction-agreement>Next Token Prediction Agreement</h3> <p>We examined how often the original and converted models agree on their top-k predictions.</p> <h4 id=methodology_1>Methodology</h4> <ul> <li>Use 100 text samples from different domains</li> <li>For each position, compare top-k predicted tokens</li> <li>Calculate agreement rate at different k values</li> </ul> <h4 id=results>Results</h4> <table> <thead> <tr> <th>Top-k</th> <th>Agreement Rate</th> </tr> </thead> <tbody> <tr> <td>Top-1</td> <td>76.3%</td> </tr> <tr> <td>Top-5</td> <td>84.7%</td> </tr> <tr> <td>Top-10</td> <td>88.2%</td> </tr> </tbody> </table> <p>The models show substantial agreement in their predictions, especially when considering the top-5 or top-10 candidates. This suggests that while the architectures differ, the overall predictive behavior remains largely intact.</p> <h3 id=attention-pattern-visualization>Attention Pattern Visualization</h3> <p>We visualized attention patterns from both models to understand qualitative differences.</p> <h4 id=methodology_2>Methodology</h4> <ul> <li>Select attention heads from different layers</li> <li>Generate attention maps for the same input</li> <li>Compare within-chunk and between-chunk patterns</li> </ul> <h4 id=key-observations>Key Observations</h4> <ol> <li><strong>Within-chunk patterns</strong> are remarkably similar between the models, which aligns with our theoretical understanding.</li> <li><strong>Between-chunk patterns</strong> in BSBR show more structured, block-like attention, as expected from the architectural differences.</li> <li><strong>Information routing</strong> appears to be preserved, with similar heads attending to similar features despite architectural changes.</li> </ol> <h2 id=performance-characteristics>Performance Characteristics</h2> <h3 id=inference-speed-comparison>Inference Speed Comparison</h3> <p>We compared inference speeds across different sequence lengths.</p> <h4 id=methodology_3>Methodology</h4> <ul> <li>Measure average inference time over 50 runs</li> <li>Test sequence lengths from 128 to 8192</li> <li>Compare on both CPU and GPU (when available)</li> </ul> <h4 id=results_1>Results</h4> <table> <thead> <tr> <th>Sequence Length</th> <th>Standard (ms)</th> <th>BSBR (ms)</th> <th>Speedup</th> </tr> </thead> <tbody> <tr> <td>128</td> <td>12.4</td> <td>18.7</td> <td>0.66x</td> </tr> <tr> <td>512</td> <td>51.2</td> <td>62.6</td> <td>0.82x</td> </tr> <tr> <td>1024</td> <td>102.7</td> <td>98.3</td> <td>1.04x</td> </tr> <tr> <td>2048</td> <td>210.3</td> <td>174.2</td> <td>1.21x</td> </tr> <tr> <td>4096</td> <td>463.8</td> <td>316.1</td> <td>1.47x</td> </tr> <tr> <td>8192</td> <td>OOM</td> <td>643.5</td> <td>∞</td> </tr> </tbody> </table> <p>These results confirm our hypothesis: standard transformers are faster for short sequences, but BSBR becomes more efficient as sequence length increases. The crossover point occurs around 1024 tokens.</p> <blockquote> <p>Note: "OOM" indicates "Out of Memory" error on the test hardware.</p> </blockquote> <h3 id=memory-usage-analysis>Memory Usage Analysis</h3> <p>We measured peak memory consumption during inference.</p> <h4 id=methodology_4>Methodology</h4> <ul> <li>Track peak memory allocation using PyTorch utilities</li> <li>Test with batch size of 1 and varying sequence lengths</li> <li>Report GPU memory for CUDA-enabled tests</li> </ul> <h4 id=results_2>Results</h4> <table> <thead> <tr> <th>Sequence Length</th> <th>Standard (MB)</th> <th>BSBR (MB)</th> <th>Ratio</th> </tr> </thead> <tbody> <tr> <td>128</td> <td>524</td> <td>603</td> <td>1.15x</td> </tr> <tr> <td>512</td> <td>718</td> <td>782</td> <td>1.09x</td> </tr> <tr> <td>1024</td> <td>1150</td> <td>1103</td> <td>0.96x</td> </tr> <tr> <td>2048</td> <td>2352</td> <td>1822</td> <td>0.77x</td> </tr> <tr> <td>4096</td> <td>OOM</td> <td>3185</td> <td>N/A</td> </tr> <tr> <td>8192</td> <td>OOM</td> <td>6148</td> <td>N/A</td> </tr> </tbody> </table> <p>The memory usage pattern mirrors the speed results: BSBR uses more memory for short sequences but becomes more memory-efficient for longer contexts. The memory efficiency advantages become significant at sequence lengths above 1024.</p> <h2 id=scaling-properties>Scaling Properties</h2> <h3 id=computational-complexity-analysis>Computational Complexity Analysis</h3> <p>We analyzed how computation time scales with sequence length for both architectures.</p> <h4 id=methodology_5>Methodology</h4> <ul> <li>Measure inference time for different sequence lengths</li> <li>Fit asymptotic complexity curves</li> <li>Analyze deviation from theoretical complexity</li> </ul> <h4 id=results_3>Results</h4> <p>The empirical scaling curves confirm that BSBR achieves near-linear scaling with sequence length:</p> <ul> <li>Standard transformer: O(n^1.96) - Very close to the theoretical O(n²)</li> <li>BSBR: O(n^1.12) - Approaching the theoretical O(n)</li> </ul> <p>The deviation from ideal scaling is likely due to implementation details and overhead that becomes less significant at extreme sequence lengths.</p> <h3 id=attention-sparsity-analysis>Attention Sparsity Analysis</h3> <p>We analyzed the effective sparsity of attention matrices in both models.</p> <h4 id=methodology_6>Methodology</h4> <ul> <li>Compute the percentage of attention weights above a threshold</li> <li>Compare across different layers and sequence lengths</li> <li>Measure effective information density</li> </ul> <h4 id=results_4>Results</h4> <table> <thead> <tr> <th>Seq Length</th> <th>Std Density</th> <th>BSBR Density</th> <th>Reduction</th> </tr> </thead> <tbody> <tr> <td>128</td> <td>100%</td> <td>76.3%</td> <td>23.7%</td> </tr> <tr> <td>512</td> <td>100%</td> <td>41.6%</td> <td>58.4%</td> </tr> <tr> <td>1024</td> <td>100%</td> <td>24.8%</td> <td>75.2%</td> </tr> <tr> <td>2048</td> <td>100%</td> <td>14.2%</td> <td>85.8%</td> </tr> <tr> <td>4096</td> <td>N/A</td> <td>8.1%</td> <td>N/A</td> </tr> </tbody> </table> <p>BSBR achieves significant sparsity in attention, with the sparsity advantage growing with sequence length. This explains the computational and memory efficiency gains observed in longer contexts.</p> <h2 id=real-world-application-benchmarks>Real-World Application Benchmarks</h2> <h3 id=text-summarization>Text Summarization</h3> <p>We evaluated both models on a text summarization task with long articles.</p> <h4 id=methodology_7>Methodology</h4> <ul> <li>Use CNN/Daily Mail dataset articles (average length ~800 tokens)</li> <li>Generate summaries with both models</li> <li>Evaluate using ROUGE scores and human judgments</li> </ul> <h4 id=results_5>Results</h4> <table> <thead> <tr> <th>Model</th> <th>ROUGE-1</th> <th>ROUGE-2</th> <th>ROUGE-L</th> <th>Human Preference</th> </tr> </thead> <tbody> <tr> <td>GPT-2</td> <td>0.41</td> <td>0.19</td> <td>0.38</td> <td>38%</td> </tr> <tr> <td>BSBR-GPT-2</td> <td>0.39</td> <td>0.18</td> <td>0.37</td> <td>35%</td> </tr> <tr> <td>No Preference</td> <td>-</td> <td>-</td> <td>-</td> <td>27%</td> </tr> </tbody> </table> <p>The BSBR model maintains comparable performance on summarization tasks, with only a slight decrease in metrics and human preference.</p> <h3 id=long-context-qa>Long-Context QA</h3> <p>We tested the models on question-answering tasks that require processing long contexts.</p> <h4 id=methodology_8>Methodology</h4> <ul> <li>Use custom dataset with questions requiring context from 2000+ tokens away</li> <li>Compare answer accuracy between models</li> <li>Measure inference time for complete processing</li> </ul> <h4 id=results_6>Results</h4> <table> <thead> <tr> <th>Model</th> <th>Accuracy</th> <th>Avg. Inference Time (s)</th> </tr> </thead> <tbody> <tr> <td>GPT-2</td> <td>58.3%</td> <td>4.7</td> </tr> <tr> <td>BSBR-GPT-2</td> <td>56.9%</td> <td>3.2</td> </tr> </tbody> </table> <p>The BSBR model achieves comparable accuracy with a 32% reduction in inference time for this long-context task.</p> <h2 id=effect-of-hyperparameters>Effect of Hyperparameters</h2> <h3 id=chunk-size-impact>Chunk Size Impact</h3> <p>We investigated how chunk size affects model performance and efficiency.</p> <h4 id=methodology_9>Methodology</h4> <ul> <li>Test BSBR models with chunk sizes: 64, 128, 256, 512</li> <li>Measure inference speed and memory usage</li> <li>Evaluate output quality metrics</li> </ul> <h4 id=results_7>Results</h4> <table> <thead> <tr> <th>Chunk Size</th> <th>Speed (rel.)</th> <th>Memory (rel.)</th> <th>Output Similarity</th> </tr> </thead> <tbody> <tr> <td>64</td> <td>1.00x</td> <td>1.00x</td> <td>0.87</td> </tr> <tr> <td>128</td> <td>0.92x</td> <td>1.05x</td> <td>0.83</td> </tr> <tr> <td>256</td> <td>0.85x</td> <td>1.12x</td> <td>0.79</td> </tr> <tr> <td>512</td> <td>0.78x</td> <td>1.23x</td> <td>0.72</td> </tr> </tbody> </table> <p>Smaller chunk sizes maintain closer similarity to the original model but sacrifice some of the speed benefits. Larger chunks improve computational efficiency but diverge more from the original model's behavior.</p> <h3 id=compression-factor-analysis>Compression Factor Analysis</h3> <p>We explored how state vector compression affects model performance.</p> <h4 id=methodology_10>Methodology</h4> <ul> <li>Test compression factors: None, 2, 4, 8</li> <li>Measure impact on memory usage and inference speed</li> <li>Evaluate accuracy on benchmark tasks</li> </ul> <h4 id=results_8>Results</h4> <table> <thead> <tr> <th>Compression</th> <th>Memory Saved</th> <th>Speed Impact</th> <th>Accuracy Drop</th> </tr> </thead> <tbody> <tr> <td>None</td> <td>0%</td> <td>0%</td> <td>0%</td> </tr> <tr> <td>2x</td> <td>22.3%</td> <td>+1.2%</td> <td>0.4%</td> </tr> <tr> <td>4x</td> <td>36.1%</td> <td>+2.8%</td> <td>1.7%</td> </tr> <tr> <td>8x</td> <td>42.5%</td> <td>+3.5%</td> <td>3.8%</td> </tr> </tbody> </table> <p>A compression factor of 2-4 offers a good tradeoff, providing substantial memory savings with minimal impact on model performance.</p> <h2 id=fine-tuning-analysis>Fine-Tuning Analysis</h2> <h3 id=recovery-of-conversion-loss>Recovery of Conversion Loss</h3> <p>We investigated whether fine-tuning can recover any performance loss after conversion.</p> <h4 id=methodology_11>Methodology</h4> <ul> <li>Fine-tune converted model for 1, 5, and 10 epochs</li> <li>Evaluate on benchmark tasks after each phase</li> <li>Compare with original model performance</li> </ul> <h4 id=results_9>Results</h4> <table> <thead> <tr> <th>Model</th> <th>ROUGE-L</th> <th>QA Accuracy</th> <th>Human Preference</th> </tr> </thead> <tbody> <tr> <td>Original GPT-2</td> <td>0.38</td> <td>58.3%</td> <td>38%</td> </tr> <tr> <td>BSBR (no tuning)</td> <td>0.37</td> <td>56.9%</td> <td>35%</td> </tr> <tr> <td>BSBR (1 epoch)</td> <td>0.37</td> <td>57.4%</td> <td>36%</td> </tr> <tr> <td>BSBR (5 epochs)</td> <td>0.38</td> <td>58.1%</td> <td>37%</td> </tr> <tr> <td>BSBR (10 epochs)</td> <td>0.38</td> <td>58.4%</td> <td>39%</td> </tr> </tbody> </table> <p>Even a modest amount of fine-tuning helps recover most of the performance gap, and extended fine-tuning can lead to performance that matches or exceeds the original model.</p> <h2 id=conclusions>Conclusions</h2> <p>Our research on converting standard transformers to BSBR yields several important findings:</p> <ol> <li> <p><strong>Behavior preservation</strong> is significant but not perfect. The converted models maintain 70-85% similarity in outputs and predictions.</p> </li> <li> <p><strong>Performance crossover</strong> occurs around the 1024-token mark, where BSBR begins to outperform standard transformers in both speed and memory usage.</p> </li> <li> <p><strong>Asymptotic efficiency</strong> is substantially better for BSBR, with near-linear scaling observed empirically.</p> </li> <li> <p><strong>Practical viability</strong> is confirmed for real-world tasks, with only modest performance degradation that can be recovered through fine-tuning.</p> </li> <li> <p><strong>Hyperparameter tuning</strong> allows balancing between computational efficiency and output fidelity.</p> </li> </ol> <p>These findings demonstrate that converting pre-trained transformers to BSBR is a viable approach for extending the capabilities of existing models to handle longer contexts more efficiently.</p> <h2 id=future-research-directions>Future Research Directions</h2> <p>Based on our findings, we identify several promising directions for future research:</p> <ol> <li><strong>Architecture-specific optimizations</strong> to further improve converted model performance</li> <li><strong>Hybrid attention mechanisms</strong> that dynamically switch between standard and BSBR attention</li> <li><strong>Layer-wise conversion strategies</strong> that apply BSBR selectively to specific layers</li> <li><strong>Specialized fine-tuning techniques</strong> for converted models</li> <li><strong>Hardware-specific optimizations</strong> to better leverage modern accelerators </li> </ol> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime" title="March 29, 2025 08:20:59">March 29, 2025 08:20:59</span> </span> </aside> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../..", "features": ["navigation.tabs", "navigation.sections", "navigation.expand", "navigation.top", "search.suggest", "search.highlight", "content.tabs.link", "content.code.annotation", "content.code.copy"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../../assets/javascripts/bundle.c8b220af.min.js></script> </body> </html>